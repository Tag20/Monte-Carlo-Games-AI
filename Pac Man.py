from random import choice, random
from turtle import *
from freegames import floor, vector

state = {'score': 0}
path = Turtle(visible=False)
writer = Turtle(visible=False)
aim = vector(5, 0)
pacman = vector(-40, -80)

ghosts = [
    [vector(-180, 160), vector(5, 0)],
    [vector(-180, -160), vector(0, 5)],
    [vector(100, 160), vector(0, -5)],
    [vector(100, -160), vector(-5, 0)],
]

action_values = {}  # Stores state-action values for Monte Carlo learning
# Game Map: 20x20 Grid (0 = Wall, 1 = Food)
tiles = [
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,
    0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,
    0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
    0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
]

def world():
    """Draw the game world using the path turtle."""
    bgcolor('black')
    path.color('blue')

    for index in range(len(tiles)):
        tile = tiles[index]

        if tile > 0:
            x = (index % 20) * 20 - 200
            y = 180 - (index // 20) * 20
            square(x, y)

            if tile == 1:
                path.up()
                path.goto(x + 10, y + 10)
                path.dot(2, 'white')

def get_state(ghost):
    """Return a tuple representing the ghost's state."""
    return (floor(ghost.x, 20), floor(ghost.y, 20))

def offset(point):
    """Return the index of the tile in the tiles array for the given point."""
    x = (floor(point.x, 20) + 200) / 20
    y = (180 - floor(point.y, 20)) / 20
    index = int(x + y * 20)
    return index

def change(x, y):
    """Change Pac-Man's direction if valid."""
    if valid(pacman + vector(x, y)):
        aim.x = x
        aim.y = y

def valid(point):
    """Return True if the point is valid in tiles."""
    index = offset(point)

    # Check if the tile at the point is not a wall (assuming 0 = wall, 1 = open path)
    if tiles[index] == 0:
        return False

    index = offset(point + 19)

    if tiles[index] == 0:
        return False

    return point.x % 20 == 0 or point.y % 20 == 0

def square(x, y):
    """Draw a square at (x, y) with a given color."""
    path.up()
    path.goto(x, y)
    path.down()
    path.begin_fill()
    for _ in range(4):
        path.forward(20)
        path.left(90)
    path.end_fill()

def monte_carlo_ghost(ghost, epsilon=0.2):
    """Use Monte Carlo method to determine ghost movement."""
    state = get_state(ghost)
    actions = [vector(5, 0), vector(-5, 0), vector(0, 5), vector(0, -5)]
    
    if random() < epsilon or state not in action_values:
        return choice(actions)  # Exploration
    
    return max(action_values[state], key=action_values[state].get)  # Exploitation

def update_action_values(state, action, reward):
    """Update Monte Carlo action values."""
    if state not in action_values:
        action_values[state] = {vector(5, 0): 0, vector(-5, 0): 0, vector(0, 5): 0, vector(0, -5): 0}
    
    action_values[state][action] += reward

def move():
    """Move pacman and all ghosts."""
    global state  # Declare state as global to access it
    
    writer.undo()
    writer.write(state['score'])
    clear()

    if valid(pacman + aim):
        pacman.move(aim)
    
    index = offset(pacman)
    if tiles[index] == 1:
        tiles[index] = 2
        state['score'] += 1
        x = (index % 20) * 20 - 200
        y = 180 - (index // 20) * 20
        square(x, y)
    
    up()
    goto(pacman.x + 10, pacman.y + 10)
    dot(20, 'yellow')

    for ghost, course in ghosts:
        ghost_state = get_state(ghost)  # Use a different variable for ghost's state
        new_action = monte_carlo_ghost(ghost)
        
        if valid(ghost + new_action):
            ghost.move(new_action)
            update_action_values(ghost_state, new_action, -1)  # Reward negative to avoid walls
        else:
            update_action_values(ghost_state, new_action, -10)  # Larger penalty for hitting walls
        
        up()
        goto(ghost.x + 10, ghost.y + 10)
        dot(20, 'red')

    update()

    for ghost, _ in ghosts:
        if abs(pacman - ghost) < 20:
            return
    
    ontimer(move, 100)


setup(420, 420, 370, 0)
hideturtle()
tracer(False)
writer.goto(160, 160)
writer.color('white')
writer.write(state['score'])
listen()
onkey(lambda: change(5, 0), 'Right')
onkey(lambda: change(-5, 0), 'Left')
onkey(lambda: change(0, 5), 'Up')
onkey(lambda: change(0, -5), 'Down')
world()
move()
done()
